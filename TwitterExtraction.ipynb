{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation analysis between the Bitcoin currency and Twitter\n",
    "\n",
    "This project consists of a correlation analysis between the Bitcoin currency and tweets. In order to define the positiveness of a tweet (if the course of the bitcoin will go up or down), we realise a sentiment analysis of each tweet using the VADER algorithm. Finally we try to find a correlation between the two and we will make some machine learning to make predictions.\n",
    "\n",
    "This notebook was written using Python 3.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the currency\n",
    "#CURRENCY = \"zilliqa\"\n",
    "#CURRENCY_SYMBOL = \"ZIL\"\n",
    "CURRENCY = \"nexo\"\n",
    "CURRENCY_SYMBOL = \"NEXO\"\n",
    "#CURRENCY = \"bitcoin\"\n",
    "#CURRENCY_SYMBOL = \"BTC\"\n",
    "\n",
    "tweets_raw_file = f'data/twitter/{CURRENCY_SYMBOL}/{CURRENCY}_tweets_raw.csv'\n",
    "tweets_clean_file = f'data/twitter/{CURRENCY_SYMBOL}/{CURRENCY}_tweets_clean.csv'\n",
    "query = f'#{CURRENCY} OR #{CURRENCY_SYMBOL} OR {CURRENCY} OR ${CURRENCY} OR ${CURRENCY_SYMBOL}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Twython\n",
    "We use the *twython* package as my Python interface with the Twitter API: https://twython.readthedocs.io/en/latest/usage/starting_out.html\n",
    "\n",
    "The twython package must be installed using *pip install twython* from the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from twython import Twython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OAuth2 Authentication (*app* authentication)\n",
    "Here we use the method *OAuth2* along with the Twithon library to authenticate on the twitter API.\n",
    "\n",
    "OAuth1 will give you *user* access to the API, whereas OAuth2 will give the *app* access. For academic use the rate limits are generally better for *OAuth2* (app) authentication, with a few exceptions. For a chart showing the API limits for user and app authentication for the various parts of the Twitter API, see this chart: https://dev.twitter.com/rest/public/rate-limits\n",
    "\n",
    "Running the code block below shows that we now have a rate limit of 450 API calls. This means we can make 450 different calls to the API within the current 15-minute window. With the search API we can access 100 tweets per call. This means that, if we were downloading tweets with a specific hashtag, such as *#arnova16*, we could download 450 $\\times$ 100 or 45,000 tweets per window. This is much better than the 18,000 tweets we can access using the OAuth1 or user authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/search/tweets': {'limit': 450, 'remaining': 146, 'reset': 1527596179}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APP_KEY = 'mPQKoRwd2Pb9qpQyQmyG5s8KR'\n",
    "APP_SECRET = 'HLvIhusvfzDLKaRXY8CnZGP143kp3E3f2KqQBIEMfVL5mOxZjq'\n",
    "twitter = Twython(APP_KEY, APP_SECRET, oauth_version=2)\n",
    "ACCESS_TOKEN = twitter.obtain_access_token()\n",
    "twitter = Twython(APP_KEY, access_token=ACCESS_TOKEN)\n",
    "twitter.get_application_rate_limit_status()['resources']['search']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the twitter API\n",
    "Here we query the twitter API to get the latest tweets about bitcoin. Then we transform it to store only the useful data inside a Pandas Dataframe.\n",
    "\n",
    "The following fields are retrieved from the response:\n",
    "\n",
    "- **id** (int) : unique identifier of the tweet\n",
    "- **text** (string) : UTF-8 textual content of the tweet, max 140 chars\n",
    "- user\n",
    "  - **name** (string) : twitter's pseudo of the user\n",
    "  - **followers_count** (int) : Number of followers the user has\n",
    "- **retweet_count** (int) : Number of times the tweet has been retweeted\n",
    "- **favorite_count** (int) : Number of likes\n",
    "- **created_at** (datetime) : creation date and time of the tweet\n",
    "\n",
    "Also, we wanted to retrieve the following fields but it is not possible with the standard free API, Enteprise or premium is needed (https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object.html):\n",
    "\n",
    "- reply_count (int) : Number of times the Tweet has been replied to\n",
    "\n",
    "The pandas package must be installed using *pip install pandas* from the command line.\n",
    "\n",
    "For the search we used opertatons that are explained here (https://lifehacker.com/search-twitter-more-efficiently-with-these-search-opera-1598165519) to not only search by hashtag but also the tweets that contain the currency name or that have the hashtag with the currency's abreviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import json\n",
    "import pandas as pd\n",
    "import io\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 26/400 [00:12<02:56,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 2577, waiting for 15 minutes until next queries\n",
      "No more new tweets, stopping...\n"
     ]
    }
   ],
   "source": [
    "NUMBER_OF_QUERIES = 400\n",
    "data = {\"statuses\": []}\n",
    "next_id = \"\"\n",
    "with open(tweets_raw_file,\"a+\", encoding='utf-8') as f:\n",
    "    f.write(\"ID,Text,UserName,UserFollowerCount,RetweetCount,Likes,CreatedAt\\n\")\n",
    "    while(True):\n",
    "        last_size = 0\n",
    "        for i in tqdm(range(NUMBER_OF_QUERIES)):\n",
    "            if not next_id:\n",
    "                data = twitter.search(q=query, lang='en', result_type='recent', count=\"100\") # Use since_id for tweets after id\n",
    "            else:\n",
    "                data[\"statuses\"].extend(twitter.search(q=query, lang='en', result_type='mixed', count=\"100\", max_id=next_id)[\"statuses\"])\n",
    "            if len(data[\"statuses\"]) > 1:\n",
    "                next_id = data[\"statuses\"][len(data[\"statuses\"]) - 1]['id']\n",
    "            if last_size + 1 == len(data[\"statuses\"]):\n",
    "                break\n",
    "            else:\n",
    "                last_size = len(data[\"statuses\"])\n",
    "\n",
    "        print('Retrieved {0}, waiting for 15 minutes until next queries'.format(len(data[\"statuses\"])))\n",
    "        d = pd.DataFrame([[s[\"id\"], s[\"text\"].replace('\\n','').replace('\\r',''), s[\"user\"][\"name\"], s[\"user\"][\"followers_count\"], s[\"retweet_count\"], s[\"favorite_count\"], s[\"created_at\"]] for s in data[\"statuses\"]], columns=('ID', 'Text', 'UserName', \"UserFollowerCount\", 'RetweetCount', 'Likes', \"CreatedAt\"))\n",
    "        d.to_csv(f, mode='a', encoding='utf-8',index=False,header=False)\n",
    "        if last_size + 1 == len(data[\"statuses\"]):\n",
    "            print('No more new tweets, stopping...')\n",
    "            break\n",
    "        data[\"statuses\"] = []\n",
    "        \n",
    "        \n",
    "\n",
    "        sleep(910)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Now we will cleanup the data.\n",
    "\n",
    "We already filtered tweets in english in the call to the Twitter API.\n",
    "We will now filter links, @Pseudo, images, videos, unhashtag #happy -> happy.\n",
    "\n",
    "We won't transform to lower case because Vader take capital letters into consideration to emphasize sentiments.\n",
    "\n",
    "You must install `pip install tqdm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2577 [00:00<?, ?it/s]\n",
      " 10%|▉         | 257/2577 [00:00<00:00, 2566.91it/s]\n",
      " 20%|█▉        | 505/2577 [00:00<00:00, 2500.13it/s]\n",
      " 31%|███▏      | 808/2577 [00:00<00:00, 2557.93it/s]\n",
      " 41%|████▏     | 1068/2577 [00:00<00:00, 2562.04it/s]\n",
      " 52%|█████▏    | 1329/2577 [00:00<00:00, 2566.22it/s]\n",
      " 63%|██████▎   | 1628/2577 [00:00<00:00, 2572.47it/s]\n",
      " 73%|███████▎  | 1886/2577 [00:00<00:00, 2569.12it/s]\n",
      " 85%|████████▍ | 2182/2577 [00:00<00:00, 2571.31it/s]\n",
      " 94%|█████████▍| 2425/2577 [00:00<00:00, 2551.14it/s]\n",
      "100%|██████████| 2577/2577 [00:01<00:00, 2531.93it/s]"
     ]
    }
   ],
   "source": [
    "import re # regular expressions\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "\n",
    "d = pd.read_csv(tweets_raw_file)\n",
    "for i,s in enumerate(tqdm(d['Text'])):\n",
    "    text = d.loc[i, 'Text']\n",
    "    text = text.replace(\"#\", \"\")\n",
    "    text = re.sub('https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub('@\\\\w+ *', '', text, flags=re.MULTILINE)\n",
    "    d.loc[i, 'Text'] = text\n",
    "f = open(tweets_clean_file, 'a+', encoding='utf-8')\n",
    "d.to_csv(f, header=True, encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>UserName</th>\n",
       "      <th>UserFollowerCount</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>Likes</th>\n",
       "      <th>CreatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001426024406634497</td>\n",
       "      <td>RT : Nexo Maersk inbound APM Terminal Valencia...</td>\n",
       "      <td>Heric ♥‿♥ Montalvo</td>\n",
       "      <td>434</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tue May 29 11:32:24 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001425728255266816</td>\n",
       "      <td>$NEXO is a good project and a good buy at thes...</td>\n",
       "      <td>Trader Afrique</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Tue May 29 11:31:13 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001425151039160320</td>\n",
       "      <td>eBay: New &amp;amp; Sealed LEGO Nexo Knights King'...</td>\n",
       "      <td>US LEGO Set Sales</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tue May 29 11:28:56 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001424956675129349</td>\n",
       "      <td>RT : Nexo Community is now the largest crypto ...</td>\n",
       "      <td>Nanda Dwi Harto</td>\n",
       "      <td>3</td>\n",
       "      <td>571</td>\n",
       "      <td>0</td>\n",
       "      <td>Tue May 29 11:28:09 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001424234139222016</td>\n",
       "      <td>RT : Cryptune retirement bags 🎲💜💎🌊🎲$DBIX - Pal...</td>\n",
       "      <td>Crypto_Huey</td>\n",
       "      <td>84</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>Tue May 29 11:25:17 +0000 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                                               Text  \\\n",
       "0  1001426024406634497  RT : Nexo Maersk inbound APM Terminal Valencia...   \n",
       "1  1001425728255266816  $NEXO is a good project and a good buy at thes...   \n",
       "2  1001425151039160320  eBay: New &amp; Sealed LEGO Nexo Knights King'...   \n",
       "3  1001424956675129349  RT : Nexo Community is now the largest crypto ...   \n",
       "4  1001424234139222016  RT : Cryptune retirement bags 🎲💜💎🌊🎲$DBIX - Pal...   \n",
       "\n",
       "             UserName  UserFollowerCount  RetweetCount  Likes  \\\n",
       "0  Heric ♥‿♥ Montalvo                434             1      0   \n",
       "1      Trader Afrique                229             0      2   \n",
       "2   US LEGO Set Sales                150             0      0   \n",
       "3     Nanda Dwi Harto                  3           571      0   \n",
       "4         Crypto_Huey                 84           124      0   \n",
       "\n",
       "                        CreatedAt  \n",
       "0  Tue May 29 11:32:24 +0000 2018  \n",
       "1  Tue May 29 11:31:13 +0000 2018  \n",
       "2  Tue May 29 11:28:56 +0000 2018  \n",
       "3  Tue May 29 11:28:09 +0000 2018  \n",
       "4  Tue May 29 11:25:17 +0000 2018  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = pd.read_csv(tweets_clean_file)\n",
    "df_clean.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                                  997843451952615424\n",
       "Text                 \"Centaur Knight Mech takes it to the Nexo leve...\n",
       "UserFollowerCount                                                    0\n",
       "RetweetCount                                                         0\n",
       "Likes                                                                0\n",
       "CreatedAt                               Fri May 25 00:00:02 +0000 2018\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
